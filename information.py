import os
import json
import datetime
import random
import logging
import re
import difflib
from typing import List, Tuple

import gspread
from google.oauth2.service_account import Credentials as GCredentials
import openai  # ëª¨ë“ˆ ì „ì²´ import

# â”€â”€ ì„œë¹„ìŠ¤ ê³„ì • JSON: env var ìš°ì„ , ì—†ìœ¼ë©´ ë¡œì»¬ íŒŒì¼ì—ì„œ ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
service_json = os.getenv("GSHEET_CREDENTIALS_JSON", "")
if service_json:
    try:
        creds_info = json.loads(service_json)
    except json.JSONDecodeError as e:
        raise ValueError(f"âŒ SERVICE_ACCOUNT_JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
else:
    json_path = os.path.join(os.path.dirname(__file__), "focus-2025-458906-311d04096c93.json")
    if not os.path.exists(json_path):
        raise ValueError("âŒ í™˜ê²½ë³€ìˆ˜ 'GSHEET_CREDENTIALS_JSON'ì´ ì—†ê³ , ë¡œì»¬ JSON íŒŒì¼ë„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    with open(json_path, "r", encoding="utf-8") as f:
        creds_info = json.load(f)

if "private_key" not in creds_info or not creds_info["private_key"].startswith("-----BEGIN PRIVATE KEY-----"):
    raise ValueError("âŒ ì˜ëª»ëœ ì„œë¹„ìŠ¤ ê³„ì • JSONì…ë‹ˆë‹¤.")

# â–¶ Google Sheets/Drive ì¸ì¦ ê°ì²´ ìƒì„±
SCOPES = [
    "https://spreadsheets.google.com/feeds",
    "https://www.googleapis.com/auth/drive"
]
gs_creds = GCredentials.from_service_account_info(creds_info, scopes=SCOPES)

# âœ… OpenAI API í‚¤ ì„¤ì • (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    OPENAI_API_KEY = os.getenv("OPENAI_KEY") or os.getenv("OPENAI_SECRET")

# â”€â”€ ì¶”ê°€: .env íŒŒì¼ì´ ìˆìœ¼ë©´ ì—¬ê¸°ì„œë„ ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if not OPENAI_API_KEY:
    env_path = os.path.join(os.path.dirname(__file__), ".env")
    if os.path.exists(env_path):
        with open(env_path, encoding="utf-8") as f:
            for line in f:
                if line.strip().startswith("OPENAI_API_KEY"):
                    key = line.strip().split("=", 1)[1].strip().strip('"')
                    if key:
                        OPENAI_API_KEY = key
                        break

if not OPENAI_API_KEY:
    raise ValueError("âŒ í™˜ê²½ë³€ìˆ˜ 'OPENAI_API_KEY'ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")
openai.api_key = OPENAI_API_KEY
client = openai

# â”€â”€ ì„¤ì •ì •ë³´ì‹œíŠ¸ë¡œë¶€í„° SOURCE_DB_ID, TARGET_DB_ID ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
CONFIG_SHEET_ID = "1h8FcZcDPFsCsdnHaLhDvr8WI2mQpd9raU0YLZ7KW8_8"
config_sheet = gspread.authorize(gs_creds).open_by_key(CONFIG_SHEET_ID).sheet1
config = config_sheet.get_all_records()[0]
input_db_url = config.get("ì…ë ¥ DB ì£¼ì†Œ")
posting_db_url = config.get("í¬ìŠ¤íŒ… DB ì£¼ì†Œ")
SOURCE_DB_ID = re.search(r"/d/([a-zA-Z0-9-_]+)", input_db_url).group(1) if input_db_url else None
TARGET_DB_ID = re.search(r"/d/([a-zA-Z0-9-_]+)", posting_db_url).group(1) if posting_db_url else None

# ìƒìˆ˜ ì •ì˜
SIMILARITY_THRESHOLD = 0.5
MAX_RETRIES          = 5

def init_worksheet(sheet_id: str, sheet_name: str, header: List[str] = None):
    ws = gspread.authorize(gs_creds).open_by_key(sheet_id).worksheet(sheet_name)
    if header:
        first = ws.get_all_values()[:1]
        if not first or all(cell == "" for cell in first[0]):
            ws.clear()
            ws.append_row(header)
    return ws

def calculate_similarity(a: str, b: str) -> float:
    return difflib.SequenceMatcher(None, a, b).ratio()

def clean_content(text: str) -> str:
    return re.sub(r'(?m)^(ì„œë¡ |ë¬¸ì œ ìƒí™©|ì‹¤ë¬´ íŒ|ê²°ë¡ )\[:-]?\s\*', '', text).strip()

def build_messages_from_prompt(cfg: List[str], title: str, content: str) -> List[dict]:
    purpose, tone, para, emphasis, fmt, etc = cfg
    system = f"{purpose}\n\n{tone}\n\n{para}\n\n{emphasis}\n\n{fmt}\n\n{etc}"
    user = f"ë‹¤ìŒ ê¸€ì„ ì¤‘ë³µë˜ì§€ ì•Šë„ë¡ ì¬ì‘ì„±í•´ì¤˜:\n\nì œëª©: {title}\në‚´ìš©: {content}"
    return [
        {"role": "system", "content": system.strip()},
        {"role": "user",   "content": user.strip()},
    ]

def regenerate_unique_post(
    original_title: str,
    original: str,
    existing_texts: List[str],
    prompt_cfg: List[str],
    model_name: str,
) -> Tuple[str, float, int]:
    regen, score = original, 1.0
    for i in range(1, MAX_RETRIES + 1):
        msgs = build_messages_from_prompt(prompt_cfg, original_title, original)
        etc_lower = prompt_cfg[-1].lower()
        max_tokens = 3000
        if '2500ì' in etc_lower:
            max_tokens = 2500
        elif '2000ì' in etc_lower:
            max_tokens = 2000

        try:
            resp = client.ChatCompletion.create(
                model=model_name,
                messages=msgs,
                temperature=0.8,
                max_tokens=max_tokens,
            )
        except Exception as e:
            from openai.lib._old_api import APIRemovedInV1
            if isinstance(e, APIRemovedInV1) or isinstance(e, AttributeError):
                resp = openai.ChatCompletion.create(
                    model=model_name,
                    messages=msgs,
                    temperature=0.8,
                    max_tokens=max_tokens,
                )
            else:
                raise

        candidate = clean_content(resp.choices[0].message.content or '')
        sim = max((calculate_similarity(candidate, ex) for ex in existing_texts), default=0)
        if sim < SIMILARITY_THRESHOLD:
            return candidate, sim, i
        regen, score = candidate, sim

    return regen, score, MAX_RETRIES

def regenerate_title(content: str) -> str:
    try:
        resp = client.ChatCompletion.create(
            model="gpt-4-turbo",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ë§ˆì¼€íŒ… ì½˜í…ì¸  ì „ë¬¸ê°€ì•¼. ì§§ì€ ì œëª©ì„ ì‘ì„±í•´ì¤˜."},
                {"role": "user",   "content": content[:1000]},
            ],
            temperature=0.7,
            max_tokens=800,
        )
    except Exception as e:
        from openai.lib._old_api import APIRemovedInV1
        if isinstance(e, APIRemovedInV1) or isinstance(e, AttributeError):
            new_client = openai.OpenAI(api_key=openai.api_key)
            resp = new_client.chat.completions.create(
                model="gpt-4-turbo",
                messages=[
                    {"role": "system", "content": "ë„ˆëŠ” ë§ˆì¼€íŒ… ì½˜í…ì¸  ì „ë¬¸ê°€ì•¼. ì§§ì€ ì œëª©ì„ ì‘ì„±í•´ì¤˜."},
                    {"role": "user",   "content": content[:1000]},
                ],
                temperature=0.7,
                max_tokens=800,
            )
        else:
            raise
    return re.sub(r'^.*?:\s*', '', resp.choices[0].message.content.strip())

def translate_text(text: str, lang: str) -> str:
    try:
        resp = client.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": f"ë‹¤ìŒì„ {lang}ë¡œ ë²ˆì—­í•´ì¤˜."},
                {"role": "user",   "content": text},
            ],
            temperature=0.5,
            max_tokens=2000,
        )
    except Exception as e:
        from openai.lib._old_api import APIRemovedInV1
        if isinstance(e, APIRemovedInV1) or isinstance(e, AttributeError):
            new_client = openai.OpenAI(api_key=openai.api_key)
            resp = new_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": f"ë‹¤ìŒì„ {lang}ë¡œ ë²ˆì—­í•´ì¤˜."},
                    {"role": "user",   "content": text},
                ],
                temperature=0.5,
                max_tokens=2000,
            )
        else:
            raise
    return resp.choices[0].message.content.strip()

def now_str() -> str:
    return datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")

def process_regeneration():
    logging.basicConfig(level=logging.INFO)
    logging.info("ğŸ“Œ process_regeneration() ì‹œì‘")

    src_ws    = init_worksheet(SOURCE_DB_ID, "ìŠ¤í¬ë© ì‹œíŠ¸")
    prompt_ws = init_worksheet(SOURCE_DB_ID, "í”„ë¡¬í”„íŠ¸ì‹œíŠ¸")
    image_ws  = init_worksheet(SOURCE_DB_ID, "ì´ë¯¸ì§€ ì‹œíŠ¸")
    info_ws   = init_worksheet(TARGET_DB_ID, "ì •ë³´ì‹œíŠ¸")

    prompt_header = prompt_ws.row_values(1)
    col_map       = {name: idx for idx, name in enumerate(prompt_header)}
    required = [
        "ìƒì„±ì¼ì", "ì¶œì²˜", "ì´ë¯¸ì§€íƒœê·¸", "êµ¬ë¶„íƒœê·¸", "í˜„ì¬ì‚¬ìš©ì—¬ë¶€",
        "ì‘ì„±ì ì—­í•  ì„¤ëª…", "ì „ì²´ ì‘ì„± ì¡°ê±´", "ê¸€ êµ¬ì„±ë°©ì‹",
        "í•„ìˆ˜ í¬í•¨ í•­ëª©", "ë§ˆë¬´ë¦¬ ë¬¸ì¥", "ì¶”ê°€ ì§€ì‹œì‚¬í•­",
        "GPT ëª¨ë¸ë°©ì‹", "ê¸€ ê°„ê²©", "ê¸°ë³¸ gpt", "ê³ ê¸‰ gpt"
    ]
    for c in required:
        if c not in col_map:
            raise RuntimeError(f"âš ï¸ í”„ë¡¬í”„íŠ¸ì‹œíŠ¸ì— '{c}' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    if "run_count" not in col_map:
        prompt_ws.add_cols(1)
        prompt_ws.update_cell(1, len(prompt_header) + 1, "run_count")
        col_map["run_count"] = len(prompt_header)
        prompt_header.append("run_count")
    run_idx = col_map["run_count"]

    rows = src_ws.get_all_values()[1:]
    if not rows:
        logging.warning("âš ï¸ ìœ íš¨í•œ ìŠ¤í¬ë© ì½˜í…ì¸ ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return 0

    src_header  = src_ws.row_values(1)
    src_col_map = {name: idx for idx, name in enumerate(src_header)}

    total = 0
    prompts = prompt_ws.get_all_values()[1:]

    # â—†ìˆ˜ì •: ë¨¼ì € â€˜ì¶œì²˜â€™, â€˜í˜„ì¬ì‚¬ìš©ì—¬ë¶€â€™, â€˜êµ¬ë¶„íƒœê·¸â€™ê°€ ëª¨ë‘ ì¼ì¹˜í•˜ëŠ” í–‰ì„ ì°¾ëŠ”ë‹¤.
    matched_idx = None
    for i, cfg in enumerate(prompts, start=2):
        source_val = cfg[col_map["ì¶œì²˜"]].strip()
        use_val    = cfg[col_map["í˜„ì¬ì‚¬ìš©ì—¬ë¶€"]].strip().upper()
        category   = cfg[col_map["êµ¬ë¶„íƒœê·¸"]].strip()
        if source_val == "ìŠ¤í¬ë© ì‹œíŠ¸" and use_val == "Y" and category:
            matched_idx = i
            break
    if matched_idx is None:
        logging.error("âŒ ì¼ì¹˜í•˜ëŠ” í”„ë¡¬í”„íŠ¸ í–‰ì´ ì—†ìŠµë‹ˆë‹¤. ì „ì²´ ì²˜ë¦¬ ì¤‘ë‹¨.")
        return 0

    # â—†ìˆ˜ì •: ì°¾ì€ í•œ í–‰ë§Œ ì²˜ë¦¬í•˜ë„ë¡ ë£¨í”„ ì¸ë±ìŠ¤ë¥¼ ê³ ì •
    i   = matched_idx
    cfg = prompts[i - 2]

    # ê°™ì€ êµ¬ë¶„íƒœê·¸ë¥¼ ê°€ì§„ ìŠ¤í¬ë© í–‰ë§Œ ê³¨ë¼ë‚´ê¸°
    rows = [row for row in rows
            if len(row) > src_col_map["êµ¬ë¶„íƒœê·¸"]
               and row[src_col_map["êµ¬ë¶„íƒœê·¸"]].strip() == cfg[col_map["êµ¬ë¶„íƒœê·¸"]].strip()]
    if not rows:
        logging.warning(f"[í–‰ {i}] '{cfg[col_map['êµ¬ë¶„íƒœê·¸']]}'ì— í•´ë‹¹í•˜ëŠ” ìŠ¤í¬ë© ì½˜í…ì¸ ê°€ ì—†ìŠµë‹ˆë‹¤. ì „ì²´ ì²˜ë¦¬ ì¤‘ì§€.")
        return 0

    item     = random.choice(rows)
    existing = [r[src_col_map["ìš”ì•½"]] for r in rows if len(r) > src_col_map["ìš”ì•½"]]

    prev_count = int(cfg[run_idx]) if cfg[run_idx].isdigit() else 0
    interval   = int(cfg[col_map["ê¸€ ê°„ê²©"]]) if cfg[col_map["ê¸€ ê°„ê²©"]].isdigit() else 1
    basic_mod  = cfg[col_map["ê¸°ë³¸ gpt"]].strip() or "gpt-3.5-turbo"
    adv_mod    = cfg[col_map["ê³ ê¸‰ gpt"]].strip() or basic_mod

    if prev_count < interval:
        use_model = basic_mod
        new_count = prev_count + 1
    else:
        use_model = adv_mod
        new_count = 0

    prompt_fields = [
        "ì‘ì„±ì ì—­í•  ì„¤ëª…", "ì „ì²´ ì‘ì„± ì¡°ê±´", "ê¸€ êµ¬ì„±ë°©ì‹",
        "í•„ìˆ˜ í¬í•¨ í•­ëª©", "ë§ˆë¬´ë¦¬ ë¬¸ì¥", "ì¶”ê°€ ì§€ì‹œì‚¬í•­"
    ]
    prompt_cfg = [cfg[col_map[f]] for f in prompt_fields]

    orig_title = item[src_col_map["ì œëª©"]]
    orig_cont  = item[src_col_map["ìš”ì•½"]]

    content, score, _ = regenerate_unique_post(
        orig_title, orig_cont, existing, prompt_cfg, use_model
    )
    title = regenerate_title(content)

    image_tag = cfg[col_map["ì´ë¯¸ì§€íƒœê·¸"]].strip()
    img = ""
    img_header  = image_ws.row_values(1)
    img_col_map = {name: idx for idx, name in enumerate(img_header)}
    d_idx = img_col_map.get("ì´ë¯¸ì§€íƒœê·¸")
    c_idx = img_col_map.get("ì´ë¯¸ì§€url")
    if d_idx is not None and c_idx is not None and image_tag:
        candidates = [
            row[c_idx].strip() for row in image_ws.get_all_values()[1:]
            if len(row) > d_idx and row[d_idx].strip() == image_tag
               and len(row) > c_idx and row[c_idx].strip()
        ]
        if candidates:
            img = random.choice(candidates)

    en = translate_text(content, 'English')
    zh = translate_text(content, 'Chinese')
    ja = translate_text(content, 'Japanese')

    info_ws.append_row([
        now_str(),       # A: ì‘ì„±ì¼ì‹œ
        cfg[col_map["êµ¬ë¶„íƒœê·¸"]].strip(),  # B: êµ¬ë¶„íƒœê·¸
        "",              # C: ì‚¬ì´íŠ¸ ë¶„ë¥˜ (ë¹ˆì¹¸)
        title,           # D: ì œëª©
        content,         # E: ë‚´ìš©
        image_tag,       # F: ì´ë¯¸ì§€íƒœê·¸
        en,              # G: ì˜ë¬¸
        zh,              # H: ì¤‘ë¬¸
        ja,              # I: ì¼ë¬¸
        f"{score:.2f}",  # J: í‘œì ˆë¥ 
        img              # K: ì´ë¯¸ì§€url
    ])

    prompt_ws.update_cell(i, run_idx + 1, str(new_count))
    total += 1

    logging.info(f"ğŸ’° ì´ ì €ì¥ëœ ê¸€ ìˆ˜: {total}")
    return total

if __name__ == "__main__":
    process_regeneration()
