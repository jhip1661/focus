import os
import json
import datetime
import random
import logging
import re
import difflib
from typing import List, Tuple

import gspread
from google.oauth2.service_account import Credentials as GCredentials
import openai  # ëª¨ë“ˆ ì „ì²´ import

# â”€â”€ ì„œë¹„ìŠ¤ ê³„ì • JSON: env var ìš°ì„ , ì—†ìœ¼ë©´ ë¡œì»¬ íŒŒì¼ì—ì„œ ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
service_json = os.getenv("GSHEET_CREDENTIALS_JSON", "")
if service_json:
    try:
        creds_info = json.loads(service_json)
    except json.JSONDecodeError as e:
        raise ValueError(f"âŒ SERVICE_ACCOUNT_JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
else:
    json_path = os.path.join(os.path.dirname(__file__), "focus-2025-458906-311d04096c93.json")
    if not os.path.exists(json_path):
        raise ValueError("âŒ í™˜ê²½ë³€ìˆ˜ 'GSHEET_CREDENTIALS_JSON'ì´ ì—†ê³ , ë¡œì»¬ JSON íŒŒì¼ë„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    with open(json_path, "r", encoding="utf-8") as f:
        creds_info = json.load(f)

if "private_key" not in creds_info or not creds_info["private_key"].startswith("-----BEGIN PRIVATE KEY-----"):
    raise ValueError("âŒ ì˜ëª»ëœ ì„œë¹„ìŠ¤ ê³„ì • JSONì…ë‹ˆë‹¤.")

# â–¶ Google Sheets/Drive ì¸ì¦ ê°ì²´ ìƒì„±
SCOPES = [
    "https://spreadsheets.google.com/feeds",
    "https://www.googleapis.com/auth/drive"
]
gs_creds = GCredentials.from_service_account_info(creds_info, scopes=SCOPES)

# âœ… OpenAI API í‚¤ ì„¤ì •
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    OPENAI_API_KEY = os.getenv("OPENAI_KEY") or os.getenv("OPENAI_SECRET")
if not OPENAI_API_KEY:
    env_path = os.path.join(os.path.dirname(__file__), ".env")
    if os.path.exists(env_path):
        with open(env_path, encoding="utf-8") as f:
            for line in f:
                if line.strip().startswith("OPENAI_API_KEY"):
                    key = line.strip().split("=", 1)[1].strip()
                    if key:
                        OPENAI_API_KEY = key
                    break
if not OPENAI_API_KEY:
    raise ValueError("âŒ í™˜ê²½ë³€ìˆ˜ 'OPENAI_API_KEY'ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")
openai.api_key = OPENAI_API_KEY
client = openai

# â”€â”€ ì„¤ì •ì •ë³´ì‹œíŠ¸ ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
CONFIG_SHEET_ID = "1h8FcZcDPFsCsdnHaLhDvr8WI2mQpd9raU0YLZ7KW8_8"
config_sheet = gspread.authorize(gs_creds).open_by_key(CONFIG_SHEET_ID).sheet1
config = config_sheet.get_all_records()[0]
input_db_url = config.get("ì…ë ¥ DB ì£¼ì†Œ")
posting_db_url = config.get("í¬ìŠ¤íŒ… DB ì£¼ì†Œ")
SOURCE_DB_ID = re.search(r"/d/([a-zA-Z0-9-_]+)", input_db_url).group(1) if input_db_url else None
TARGET_DB_ID = re.search(r"/d/([a-zA-Z0-9-_]+)", posting_db_url).group(1) if posting_db_url else None

# âœ… ë²ˆì—­ìš© GPT ëª¨ë¸: ê°€ì¥ ì €ë ´í•œ ëª¨ë¸ë¡œ í•˜ë“œì½”ë”©
TRANSLATION_MODEL = "gpt-3.5-turbo"

SIMILARITY_THRESHOLD = 0.5
MAX_RETRIES = 5

def init_worksheet(sheet_id: str, sheet_name: str, header: List[str] = None):
    ws = gspread.authorize(gs_creds).open_by_key(sheet_id).worksheet(sheet_name)
    if header:
        first = ws.get_all_values()[:1]
        if not first or all(cell == "" for cell in first[0]):
            # âœ… ê¸°ì¡´ ë°ì´í„°ê°€ ìˆì„ ê²½ìš° ì‚­ì œí•˜ì§€ ì•Šê³  í—¤ë”ë§Œ ì¶”ê°€
            ws.append_row(header)
    return ws

def calculate_similarity(a: str, b: str) -> float:
    return difflib.SequenceMatcher(None, a, b).ratio()

def clean_content(text: str) -> str:
    return re.sub(r'(?m)^(ì„œë¡ |ë¬¸ì œ ìƒí™©|ì‹¤ë¬´ íŒ|ê²°ë¡ )[:\-]?\s*', '', text).strip()

def build_messages_from_prompt(cfg: List[str], title: str, content: str) -> List[dict]:
    purpose, tone, para, emphasis, fmt, etc = cfg
    system = f"{purpose}\n\n{tone}\n\n{para}\n\n{emphasis}\n\n{fmt}\n\n{etc}"
    user = f"ë‹¤ìŒ ê¸€ì„ ì¤‘ë³µë˜ì§€ ì•Šë„ë¡ ì¬ì‘ì„±í•´ì¤˜:\n\nì œëª©: {title}\në‚´ìš©: {content}"
    return [
        {"role": "system", "content": system.strip()},
        {"role": "user",   "content": user.strip()},
    ]

def regenerate_unique_post(original_title: str, original: str, existing_texts: List[str], prompt_cfg: List[str], model_name: str) -> Tuple[str, float, int]:
    regen, score = original, 1.0
    threshold = 0.6  # âœ… 60% ì´í•˜ë¡œ ê¸°ë³¸ ì„¤ì •

    for i in range(1, MAX_RETRIES + 1):
        msgs = build_messages_from_prompt(prompt_cfg, original_title, original)
        etc_lower = prompt_cfg[-1].lower()
        max_tokens = 3000
        if '2500ì' in etc_lower:
            max_tokens = 2500
        elif '2000ì' in etc_lower:
            max_tokens = 2000

        try:
            resp = client.ChatCompletion.create(
                model=model_name,
                messages=msgs,
                temperature=0.8,
                max_tokens=max_tokens,
            )
        except Exception as e:
            logging.warning(f"âš ï¸ GPT ìš”ì²­ ì‹¤íŒ¨ (ì‹œë„ {i}): {e}")
            continue

        candidate = clean_content(resp.choices[0].message.content or '')
        sim = max((calculate_similarity(candidate, ex) for ex in existing_texts), default=0)
        if sim < threshold:
            return candidate, sim, i
        regen, score = candidate, sim

    # âœ… MAX_RETRIES ë„ë‹¬ ì‹œ, í‘œì ˆë¥  ê¸°ì¤€ì„ 0.7(70%)ë¡œ ì™„í™”í•´ í•œ ë²ˆ ë” ì‹œë„
    logging.info(f"ğŸ” MAX_RETRIES ë„ë‹¬ - í‘œì ˆë¥  ê¸°ì¤€ì„ 0.7ë¡œ ì™„í™”í•˜ì—¬ ì¬ì‹œë„: {original_title}")
    for i in range(1, MAX_RETRIES + 1):
        try:
            resp = client.ChatCompletion.create(
                model=model_name,
                messages=msgs,
                temperature=0.8,
                max_tokens=max_tokens,
            )
        except Exception as e:
            logging.warning(f"âš ï¸ GPT ìµœì¢… ìš”ì²­ ì‹¤íŒ¨ (í‘œì ˆë¥  70% ê¸°ì¤€, ì‹œë„ {i}): {e}")
            continue

        candidate = clean_content(resp.choices[0].message.content or '')
        sim = max((calculate_similarity(candidate, ex) for ex in existing_texts), default=0)
        if sim < 0.7:
            return candidate, sim, MAX_RETRIES + i
        regen, score = candidate, sim

    return regen, score, MAX_RETRIES * 2

def regenerate_title(content: str) -> str:
    resp = client.ChatCompletion.create(
        model="gpt-4-turbo",
        messages=[
            {"role": "system", "content": "ë„ˆëŠ” ë§ˆì¼€íŒ… ì½˜í…ì¸  ì „ë¬¸ê°€ì•¼. ì§§ì€ ì œëª©ì„ ì‘ì„±í•´ì¤˜."},
            {"role": "user", "content": content[:1000]},
        ],
        temperature=0.7,
        max_tokens=800,
    )
    return re.sub(r'^.*?:\s*', '', resp.choices[0].message.content.strip())

def translate_text(text: str, lang: str) -> str:
    # âœ… í•­ìƒ gpt-3.5-turbo ì‚¬ìš©í•˜ë„ë¡ í•˜ë“œì½”ë”©
    resp = client.ChatCompletion.create(
        model=TRANSLATION_MODEL,
        messages=[
            {"role": "system", "content": f"ë‹¤ìŒì„ {lang}ë¡œ ë²ˆì—­í•´ì¤˜."},
            {"role": "user",   "content": text},
        ],
        temperature=0.5,
        max_tokens=2000,
    )
    return resp.choices[0].message.content.strip()

def now_str() -> str:
    return datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")

def process_regeneration():
    logging.basicConfig(level=logging.INFO)
    logging.info("ğŸ“Œ process_regeneration() ì‹œì‘")

    src_ws    = init_worksheet(SOURCE_DB_ID, "í™ë³´ì‹œíŠ¸")
    prompt_ws = init_worksheet(SOURCE_DB_ID, "í”„ë¡¬í”„íŠ¸ì‹œíŠ¸")
    image_ws  = init_worksheet(SOURCE_DB_ID, "ì´ë¯¸ì§€ ì‹œíŠ¸")
    info_ws   = init_worksheet(TARGET_DB_ID, "í™ë³´ì‹œíŠ¸")

    # â”€â”€ ì†ŒìŠ¤ ì‹œíŠ¸ í—¤ë” ë§µ ìƒì„±
    src_header  = src_ws.row_values(1)
    src_col_map = {name: idx for idx, name in enumerate(src_header)}

    rows  = src_ws.get_all_values()[1:]
    today = datetime.datetime.now().date()
    filtered_rows = []
    for r in rows:
        norm = re.sub(r'[\.\s]+', '-', r[1].strip())
        norm = re.sub(r'-+', '-', norm)
        try:
            dl = datetime.datetime.strptime(norm, "%Y-%m-%d").date()
        except ValueError:
            continue
        if dl >= today:
            filtered_rows.append(r)
    if not filtered_rows:
        logging.warning("âš ï¸ ìœ íš¨í•œ ë§ˆì¼€íŒ… ì½˜í…ì¸ ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return 0

    total = 0
    prompt_header = prompt_ws.row_values(1)
    col_map       = {name: idx for idx, name in enumerate(prompt_header)}
    run_idx       = col_map.get("run_count", len(prompt_header))

    prompts = prompt_ws.get_all_values()[1:]
    for i, cfg in enumerate(prompts, start=2):
        if len(cfg) <= run_idx:
            continue

        # â”€â”€â”€ ì¶œì²˜, ì‚¬ìš©ì—¬ë¶€, êµ¬ë¶„íƒœê·¸ ì„¸ ì¡°ê±´ ëª¨ë‘ ì¼ì¹˜í•˜ì§€ ì•Šìœ¼ë©´ ì¦‰ì‹œ ì¤‘ë‹¨ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        source_val = cfg[col_map["ì¶œì²˜"]].strip()
        use_val    = cfg[col_map["í˜„ì¬ì‚¬ìš©ì—¬ë¶€"]].strip().upper()
        category   = cfg[col_map["êµ¬ë¶„íƒœê·¸"]].strip()
        if not (source_val == "í™ë³´ì‹œíŠ¸" and use_val == "Y" and category):
            logging.error(
                f"âŒ í”„ë¡¬í”„íŠ¸ ì„¤ì • ì˜¤ë¥˜: ì¶œì²˜='{source_val}', í˜„ì¬ì‚¬ìš©ì—¬ë¶€='{use_val}', êµ¬ë¶„íƒœê·¸='{category}' ëª¨ë‘ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤."
            )
            raise RuntimeError("í”„ë¡¬í”„íŠ¸ í•„í„° ì¡°ê±´ ë¶ˆì¼ì¹˜ë¡œ ì‘ì—…ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

        # í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì— ë§ëŠ” í–‰ë§Œ ì¶”ì¶œ
        matching_rows = [
            row for row in filtered_rows
            if len(row) > src_col_map["êµ¬ë¶„íƒœê·¸"]
               and row[src_col_map["êµ¬ë¶„íƒœê·¸"]].strip() == category
        ]
        if not matching_rows:
            logging.info(f"âš ï¸ '{category}' êµ¬ë¶„íƒœê·¸ì— í•´ë‹¹í•˜ëŠ” ìŠ¤í¬ë© ì½˜í…ì¸ ê°€ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
            continue

        item           = random.choice(matching_rows)
        existing_texts = [r[src_col_map["ìš”ì•½"]] for r in matching_rows]

        prompt_fields = [
            "ì‘ì„±ì ì—­í•  ì„¤ëª…", "ì „ì²´ ì‘ì„± ì¡°ê±´", "ê¸€ êµ¬ì„±ë°©ì‹",
            "í•„ìˆ˜ í¬í•¨ í•­ëª©", "ë§ˆë¬´ë¦¬ ë¬¸ì¥", "ì¶”ê°€ ì§€ì‹œì‚¬í•­"
        ]
        prompt_cfg = [cfg[col_map[f]] for f in prompt_fields]

        orig_title = item[0]
        orig_cont  = item[4]

        prev_count = int(cfg[run_idx]) if cfg[run_idx].isdigit() else 0
        interval   = int(cfg[col_map["ê¸€ ê°„ê²©"]]) if cfg[col_map["ê¸€ ê°„ê²©"]].isdigit() else 1
        basic_mod  = cfg[col_map["ê¸°ë³¸ gpt"]].strip() or "gpt-3.5-turbo"
        adv_mod    = cfg[col_map["ê³ ê¸‰ gpt"]].strip() or basic_mod
        use_model  = basic_mod if prev_count < interval else adv_mod
        new_count  = prev_count + 1 if prev_count < interval else 0

        content, score, _ = regenerate_unique_post(
            orig_title, orig_cont, existing_texts, prompt_cfg, use_model
        )
        title = regenerate_title(content)

        image_tag = cfg[col_map["ì´ë¯¸ì§€íƒœê·¸"]].strip()
        img_header = image_ws.row_values(1)
        img_col_map = {name: idx for idx, name in enumerate(img_header)}
        d_idx = img_col_map.get("ì´ë¯¸ì§€íƒœê·¸")
        c_idx = img_col_map.get("ì´ë¯¸ì§€url")
        img = ""
        if d_idx is not None and c_idx is not None and image_tag:
            candidates = [
                row[c_idx].strip() for row in image_ws.get_all_values()[1:]
                if len(row) > d_idx and row[d_idx].strip() == image_tag
                   and len(row) > c_idx and row[c_idx].strip()
            ]
            if candidates:
                img = random.choice(candidates)

        en = translate_text(content, 'English')
        zh = translate_text(content, 'Chinese')
        ja = translate_text(content, 'Japanese')

        info_ws.append_row([
            now_str(), title, content, category, en, zh, ja, f"{score:.2f}", img
        ])

        prompt_ws.update_cell(i, run_idx + 1, str(new_count))
        total += 1

    logging.info(f"ğŸ’° ì´ ì €ì¥ëœ ê¸€ ìˆ˜: {total}")
    return total

if __name__ == "__main__":
    process_regeneration()
