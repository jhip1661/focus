import os
import json
import datetime
import random
import logging
import re
import difflib
from typing import List, Tuple

import gspread
from google.oauth2.service_account import Credentials as GCredentials
import openai  # ëª¨ë“ˆ ì „ì²´ import

# â”€â”€ ì„œë¹„ìŠ¤ ê³„ì • JSON: env var ìš°ì„ , ì—†ìœ¼ë©´ ë¡œì»¬ íŒŒì¼ì—ì„œ ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
service_json = os.getenv("GSHEET_CREDENTIALS_JSON", "")
if service_json:
    try:
        creds_info = json.loads(service_json)
    except json.JSONDecodeError as e:
        raise ValueError(f"âŒ SERVICE_ACCOUNT_JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
else:
    json_path = os.path.join(os.path.dirname(__file__), "focus-2025-458906-311d04096c93.json")
    if not os.path.exists(json_path):
        raise ValueError("âŒ í™˜ê²½ë³€ìˆ˜ 'GSHEET_CREDENTIALS_JSON'ì´ ì—†ê³ , ë¡œì»¬ JSON íŒŒì¼ë„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    with open(json_path, "r", encoding="utf-8") as f:
        creds_info = json.load(f)

if "private_key" not in creds_info or not creds_info["private_key"].startswith("-----BEGIN PRIVATE KEY-----"):
    raise ValueError("âŒ ì˜ëª»ëœ ì„œë¹„ìŠ¤ ê³„ì • JSONì…ë‹ˆë‹¤.")

# â–¶ Google Sheets/Drive ì¸ì¦ ê°ì²´ ìƒì„±
SCOPES = [
    "https://spreadsheets.google.com/feeds",
    "https://www.googleapis.com/auth/drive"
]
gs_creds = GCredentials.from_service_account_info(creds_info, scopes=SCOPES)

# âœ… OpenAI API í‚¤ ì„¤ì •
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    OPENAI_API_KEY = os.getenv("OPENAI_KEY") or os.getenv("OPENAI_SECRET")
if not OPENAI_API_KEY:
    env_path = os.path.join(os.path.dirname(__file__), ".env")
    if os.path.exists(env_path):
        with open(env_path, encoding="utf-8") as f:
            for line in f:
                if line.strip().startswith("OPENAI_API_KEY"):
                    key = line.strip().split("=", 1)[1].strip().strip('"')
                    if key:
                        OPENAI_API_KEY = key
                    break
if not OPENAI_API_KEY:
    raise ValueError("âŒ í™˜ê²½ë³€ìˆ˜ 'OPENAI_API_KEY'ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")
openai.api_key = OPENAI_API_KEY
client = openai

# â”€â”€ ì„¤ì •ì •ë³´ì‹œíŠ¸ ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
CONFIG_SHEET_ID = "1h8FcZcDPFsCsdnHaLhDvr8WI2mQpd9raU0YLZ7KW8_8"
config_sheet = gspread.authorize(gs_creds).open_by_key(CONFIG_SHEET_ID).sheet1
config = config_sheet.get_all_records()[0]
input_db_url = config.get("ì…ë ¥ DB ì£¼ì†Œ")
posting_db_url = config.get("í¬ìŠ¤íŒ… DB ì£¼ì†Œ")
SOURCE_DB_ID = re.search(r"/d/([a-zA-Z0-9-_]+)", input_db_url).group(1) if input_db_url else None
TARGET_DB_ID = re.search(r"/d/([a-zA-Z0-9-_]+)", posting_db_url).group(1) if posting_db_url else None

# âœ… ë²ˆì—­ìš© GPT ëª¨ë¸: ê°€ì¥ ì €ë ´í•œ ëª¨ë¸ë¡œ í•˜ë“œì½”ë”©
TRANSLATION_MODEL = "gpt-3.5-turbo"

SIMILARITY_THRESHOLD = 0.5
MAX_RETRIES = 5

def init_worksheet(sheet_id: str, sheet_name: str, header: List[str] = None):
    ws = gspread.authorize(gs_creds).open_by_key(sheet_id).worksheet(sheet_name)
    if header:
        first = ws.get_all_values()[:1]
        if not first or all(cell == "" for cell in first[0]):
            ws.append_row(header)
    return ws

def calculate_similarity(a: str, b: str) -> float:
    return difflib.SequenceMatcher(None, a, b).ratio()

def clean_content(text: str) -> str:
    return re.sub(r'(?m)^(ì„œë¡ |ë¬¸ì œ ìƒí™©|ì‹¤ë¬´ íŒ|ê²°ë¡ )[:\-]?\s*', '', text).strip()

def build_messages_from_prompt(cfg: List[str], title: str, content: str) -> List[dict]:
    purpose, tone, para, emphasis, fmt, etc = cfg
    system = f"{purpose}\n\n{tone}\n\n{para}\n\n{emphasis}\n\n{fmt}\n\n{etc}"
    user = f"ë‹¤ìŒ ê¸€ì„ ì¤‘ë³µë˜ì§€ ì•Šë„ë¡ ì¬ì‘ì„±í•´ì¤˜:\n\nì œëª©: {title}\në‚´ìš©: {content}"
    return [
        {"role": "system", "content": system.strip()},
        {"role": "user", "content": user.strip()},
    ]

def regenerate_unique_post(original_title: str, original: str, existing_texts: List[str], prompt_cfg: List[str], model_name: str) -> Tuple[str, float, int]:
    regen, score = original, 1.0
    threshold = 0.6  # âœ… 60% ì´í•˜ë¡œ ê¸°ë³¸ ì„¤ì •

    for i in range(1, MAX_RETRIES + 1):
        msgs = build_messages_from_prompt(prompt_cfg, original_title, original)
        etc_lower = prompt_cfg[-1].lower()
        max_tokens = 3000
        if '2500ì' in etc_lower:
            max_tokens = 2500
        elif '2000ì' in etc_lower:
            max_tokens = 2000

        try:
            resp = client.ChatCompletion.create(
                model=model_name,
                messages=msgs,
                temperature=0.8,
                max_tokens=max_tokens,
            )
        except Exception as e:
            logging.warning(f"âš ï¸ GPT ìš”ì²­ ì‹¤íŒ¨ (ì‹œë„ {i}): {e}")
            continue

        candidate = clean_content(resp.choices[0].message.content or '')
        sim = max((calculate_similarity(candidate, ex) for ex in existing_texts), default=0)
        if sim < threshold:
            return candidate, sim, i
        regen, score = candidate, sim

    # âœ… MAX_RETRIES ë„ë‹¬ ì‹œ, í‘œì ˆë¥  ê¸°ì¤€ì„ 0.7(70%)ë¡œ ì™„í™”í•´ í•œ ë²ˆ ë” ì‹œë„
    logging.info(f"ğŸ” MAX_RETRIES ë„ë‹¬ - í‘œì ˆë¥  ê¸°ì¤€ì„ 0.7ë¡œ ì™„í™”í•˜ì—¬ ì¬ì‹œë„: {original_title}")
    for i in range(1, MAX_RETRIES + 1):
        try:
            resp = client.ChatCompletion.create(
                model=model_name,
                messages=msgs,
                temperature=0.8,
                max_tokens=max_tokens,
            )
        except Exception as e:
            logging.warning(f"âš ï¸ GPT ìµœì¢… ìš”ì²­ ì‹¤íŒ¨ (í‘œì ˆë¥  70% ê¸°ì¤€, ì‹œë„ {i}): {e}")
            continue

        candidate = clean_content(resp.choices[0].message.content or '')
        sim = max((calculate_similarity(candidate, ex) for ex in existing_texts), default=0)
        if sim < 0.7:
            return candidate, sim, MAX_RETRIES + i
        regen, score = candidate, sim

    return regen, score, MAX_RETRIES * 2

def regenerate_title(content: str) -> str:
    resp = client.ChatCompletion.create(
        model="gpt-4-turbo",
        messages=[
            {"role": "system", "content": "ë„ˆëŠ” ë§ˆì¼€íŒ… ì½˜í…ì¸  ì „ë¬¸ê°€ì•¼. ì§§ì€ ì œëª©ì„ ì‘ì„±í•´ì¤˜."},
            {"role": "user", "content": content[:1000]},
        ],
        temperature=0.7,
        max_tokens=800,
    )
    return re.sub(r'^.*?:\s*', '', resp.choices[0].message.content.strip())

def translate_text(text: str, lang: str) -> str:
    resp = client.ChatCompletion.create(
        model=TRANSLATION_MODEL,
        messages=[
            {"role": "system", "content": f"ë‹¤ìŒì„ {lang}ë¡œ ë²ˆì—­í•´ì¤˜."},
            {"role": "user", "content": text},
        ],
        temperature=0.5,
        max_tokens=2000,
    )
    return resp.choices[0].message.content.strip()

def now_str() -> str:
    return datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")

def process_regeneration():
    logging.basicConfig(level=logging.INFO)
    logging.info("ğŸ“Œ process_regeneration() ì‹œì‘")

    src_ws    = init_worksheet(SOURCE_DB_ID, "í™ë³´ì‹œíŠ¸")
    prompt_ws = init_worksheet(SOURCE_DB_ID, "í”„ë¡¬í”„íŠ¸ì‹œíŠ¸")
    image_ws  = init_worksheet(SOURCE_DB_ID, "ì´ë¯¸ì§€ ì‹œíŠ¸")
    info_ws   = init_worksheet(TARGET_DB_ID, "í™ë³´ì‹œíŠ¸")

    # â”€â”€ ì†ŒìŠ¤ ì‹œíŠ¸ í—¤ë” ë§µ ìƒì„±
    src_header  = src_ws.row_values(1)
    src_col_map = {name: idx for idx, name in enumerate(src_header)}

    # â”€â”€ ìŠ¤í¬ë© ë°ì´í„°(ë‚ ì§œ í•„í„°ë§)
    rows  = src_ws.get_all_values()[1:]
    today = datetime.datetime.now().date()
    filtered_rows = []
    for r in rows:
        norm = re.sub(r'[\.\s]+', '-', r[1].strip())
        norm = re.sub(r'-+', '-', norm)
        try:
            dl = datetime.datetime.strptime(norm, "%Y-%m-%d").date()
        except ValueError:
            continue
        if dl >= today:
            filtered_rows.append(r)
    if not filtered_rows:
        logging.warning("âš ï¸ ìœ íš¨í•œ ë§ˆì¼€íŒ… ì½˜í…ì¸ ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return 0

    # â”€â”€ valid_rows ì™€ item ì •ì˜ ì¶”ê°€
    valid_rows = filtered_rows  # ìˆ˜ì •: í•„í„°ë§ëœ í–‰ì„ valid_rowsë¡œ ì§€ì •
    item = random.choice(valid_rows)  # ìˆ˜ì •: ëœë¤ìœ¼ë¡œ ì•„ì´í…œ ì„ íƒ

    # â”€â”€ ê¸°ì¡´ ê¸€ ë¦¬ìŠ¤íŠ¸ì—ì„œ ìê¸° ìì‹  ì œì™¸ (ì¤‘ë³µ ìƒì„± ë°©ì§€)
    existing_texts = [r[4] for r in valid_rows if r != item]  # ìˆ˜ì •: 'ìš”ì•½' ì—´ì„ í—¤ë”ê°€ ì•„ë‹ˆë¼ ì¸ë±ìŠ¤ 4ë¡œ ê³ ì •

    # â”€â”€ í”„ë¡¬í”„íŠ¸ì‹œíŠ¸ì—ì„œ 3ê°œ ì¡°ê±´ ëª¨ë‘ ì¼ì¹˜í•˜ëŠ” í–‰ ì°¾ê¸° (ìˆ˜ì •)
    prompt_header    = prompt_ws.row_values(1)
    col_map          = {name: idx for idx, name in enumerate(prompt_header)}
    run_idx          = col_map.get("run_count", len(prompt_header))
    all_prompts      = prompt_ws.get_all_values()[1:]
    matching_prompts = [
        cfg for cfg in all_prompts
        if len(cfg) > run_idx
           and cfg[col_map["ì¶œì²˜"]].strip() == "í™ë³´ì‹œíŠ¸"
           and cfg[col_map["í˜„ì¬ì‚¬ìš©ì—¬ë¶€"]].strip().upper() == "Y"
           and cfg[col_map["êµ¬ë¶„íƒœê·¸"]].strip()
    ]
    if not matching_prompts:
        raise RuntimeError("âŒ í”„ë¡¬í”„íŠ¸ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: ì¶œì²˜Â·ì‚¬ìš©ì—¬ë¶€Â·êµ¬ë¶„íƒœê·¸ ëª¨ë‘ ì¼ì¹˜í•˜ëŠ” í–‰ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    cfg      = matching_prompts[0]
    category = cfg[col_map["êµ¬ë¶„íƒœê·¸"]].strip()

    # â”€â”€ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    prompt_fields = [
        "ì‘ì„±ì ì—­í•  ì„¤ëª…", "ì „ì²´ ì‘ì„± ì¡°ê±´", "ê¸€ êµ¬ì„±ë°©ì‹",
        "í•„ìˆ˜ í¬í•¨ í•­ëª©", "ë§ˆë¬´ë¦¬ ë¬¸ì¥", "ì¶”ê°€ ì§€ì‹œì‚¬í•­"
    ]
    prompt_cfg    = [cfg[col_map[f]] for f in prompt_fields]

    # â”€â”€ ê¸€ ìƒì„± íŒŒë¼ë¯¸í„° ê³„ì‚°
    orig_title = item[0]
    orig_cont  = item[4]
    prev_count = int(cfg[run_idx]) if cfg[run_idx].isdigit() else 0
    interval   = int(cfg[col_map["ê¸€ ê°„ê²©"]]) if cfg[col_map["ê¸€ ê°„ê²©"]].isdigit() else 1
    basic_mod  = cfg[col_map["ê¸°ë³¸ gpt"]].strip() or "gpt-3.5-turbo"
    adv_mod    = cfg[col_map["ê³ ê¸‰ gpt"]].strip() or basic_mod
    use_model  = basic_mod if prev_count < interval else adv_mod
    new_count  = prev_count + 1 if prev_count < interval else 0

    content, score, _ = regenerate_unique_post(
        orig_title, orig_cont, existing_texts, prompt_cfg, use_model
    )
    title = regenerate_title(content)

    # â”€â”€ ì´ë¯¸ì§€ íƒœê·¸ ë§¤ì¹­
    image_tag = cfg[col_map["ì´ë¯¸ì§€íƒœê·¸"]].strip()
    img_header  = image_ws.row_values(1)
    img_col_map = {name: idx for idx, name in enumerate(img_header)}
    d_idx = img_col_map.get("ì´ë¯¸ì§€íƒœê·¸")
    c_idx = img_col_map.get("ì´ë¯¸ì§€url")
    img   = ""
    if d_idx is not None and c_idx is not None and image_tag:
        candidates = [
            row[c_idx].strip() for row in image_ws.get_all_values()[1:]
            if len(row) > d_idx and row[d_idx].strip() == image_tag
               and len(row) > c_idx and row[c_idx].strip()
        ]
        if candidates:
            img = random.choice(candidates)

    # â”€â”€ ë‹¤êµ­ì–´ ë²ˆì—­
    en = translate_text(content, 'English')
    zh = translate_text(content, 'Chinese')
    ja = translate_text(content, 'Japanese')

    # â”€â”€ ê²°ê³¼ ê¸°ë¡
    info_ws.append_row([
        now_str(), title, content, category, en, zh, ja, f"{score:.2f}", img
    ])

    # â”€â”€ run_count ì—…ë°ì´íŠ¸
    prompt_ws.update_cell(
        all_prompts.index(cfg) + 2,  # ì‹¤ì œ ì‹œíŠ¸ í–‰ ë²ˆí˜¸
        run_idx + 1,
        str(new_count)
    )

    logging.info("ğŸ’° í•œ ê±´ì˜ ë§ˆì¼€íŒ… ì½˜í…ì¸ ê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
    return 1

if __name__ == "__main__":
    process_regeneration()
