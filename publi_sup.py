import os
import json
import datetime
import random
import logging
import re
import difflib
from typing import List, Tuple

import gspread
from google.oauth2.service_account import Credentials as GCredentials
import openai  # ‚úÖ OpenAI Î™®Îìà Ï†ÑÏ≤¥ import

# üîê ÌôòÍ≤Ω Î≥ÄÏàòÏóêÏÑú JSON Î¨∏ÏûêÏó¥ ÏùΩÍ≥† Ï§ÑÎ∞îÍøà Ï≤òÎ¶¨
CREDENTIALS_JSON = os.getenv("GSHEET_CREDENTIALS_JSON", "")
if not CREDENTIALS_JSON:
    raise ValueError("‚ùå ÌôòÍ≤ΩÎ≥ÄÏàò 'GSHEET_CREDENTIALS_JSON'Ïù¥ ÎàÑÎùΩÎêòÏóàÏäµÎãàÎã§.")
try:
    creds_info = json.loads(CREDENTIALS_JSON)
except json.JSONDecodeError as e:
    raise ValueError(f"‚ùå SERVICE_ACCOUNT_JSON ÌååÏã± Ïã§Ìå®: {e}")
if "private_key" not in creds_info or not creds_info["private_key"].startswith(
        "-----BEGIN PRIVATE KEY-----"):
    raise ValueError("‚ùå ÏûòÎ™ªÎêú ÏÑúÎπÑÏä§ Í≥ÑÏ†ï JSONÏûÖÎãàÎã§.")

# Íµ¨Í∏Ä Ïù∏Ï¶ù Í∞ùÏ≤¥ ÏÉùÏÑ±
SCOPES = [
    "https://spreadsheets.google.com/feeds",
    "https://www.googleapis.com/auth/drive"
]
gs_creds = GCredentials.from_service_account_info(creds_info, scopes=SCOPES)

# ‚úÖ OpenAI API ÌÇ§ ÏÑ§Ï†ï
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    raise ValueError("‚ùå ÌôòÍ≤ΩÎ≥ÄÏàò 'OPENAI_API_KEY'Í∞Ä ÎàÑÎùΩÎêòÏóàÏäµÎãàÎã§.")
openai.api_key = OPENAI_API_KEY
client = openai

# ÏÉÅÏàò Ï†ïÏùò
SIMILARITY_THRESHOLD = 0.6
MAX_RETRIES = 5

SOURCE_DB_ID = os.getenv("SOURCE_DB_ID")
TARGET_DB_ID = os.getenv("TARGET_DB_ID")


def init_worksheet(sheet_id: str, sheet_name: str, header: List[str] = None):
    ws = gspread.authorize(gs_creds).open_by_key(sheet_id).worksheet(
        sheet_name)
    if header:
        first = ws.get_all_values()[:1]
        if not first or all(cell == "" for cell in first[0]):
            ws.clear()
            ws.append_row(header)
    return ws


def calculate_similarity(text1: str, text2: str) -> float:
    return difflib.SequenceMatcher(None, text1, text2).ratio()


def clean_content(text: str) -> str:
    return re.sub(r'(?m)^(ÏÑúÎ°†|Î¨∏Ï†ú ÏÉÅÌô©|Ïã§Î¨¥ ÌåÅ|Í≤∞Î°†)[:\-]?\s*', "", text).strip()


def build_messages_from_prompt(prompt_config: List[str], title: str,
                               content: str) -> List[dict]:
    purpose, tone, para, emphasis, format_, etc = prompt_config
    system_msg = f"""{purpose}

{tone}

{para}

{emphasis}

{format_}

{etc}"""
    user_msg = f"""Îã§Ïùå Í∏ÄÏùÑ Ï§ëÎ≥µÎêòÏßÄ ÏïäÎèÑÎ°ù Ïû¨ÏûëÏÑ±Ìï¥Ï§ò:

Ï†úÎ™©: {title}
ÎÇ¥Ïö©: {content}"""
    return [
        {
            "role": "system",
            "content": system_msg.strip()
        },
        {
            "role": "user",
            "content": user_msg.strip()
        },
    ]


def regenerate_unique_post(
    original_title: str,
    original: str,
    existing_texts: List[str],
    prompt_config: List[str],
    model: str,
) -> Tuple[str, float, int]:
    for i in range(MAX_RETRIES):
        messages = build_messages_from_prompt(prompt_config, original_title,
                                              original)
        try:
            resp = client.ChatCompletion.create(
                model=model,
                messages=messages,
                temperature=0.8,
                max_tokens=2500,
            )
        except Exception as e:
            logging.error(f"‚ùå OpenAI API Ìò∏Ï∂ú Ïò§Î•ò (model={model}): {e}")
            raise
        regen = resp.choices[0].message.content.strip()
        regen = clean_content(regen)
        score = max(calculate_similarity(regen, t) for t in existing_texts)
        if score < SIMILARITY_THRESHOLD:
            return regen, score, i + 1
    return regen, score, MAX_RETRIES


def regenerate_title(content: str) -> str:
    system = "ÎÑàÎäî ÎßàÏºÄÌåÖ ÏΩòÌÖêÏ∏† Ï†ÑÎ¨∏Í∞ÄÏïº. ÏïÑÎûò ÎÇ¥Ïö©ÏùÑ Î≥¥Í≥† ÌÅ¥Î¶≠ÏùÑ Ïú†ÎèÑÌïòÎäî ÏßßÏùÄ Ï†úÎ™©ÏùÑ ÏûëÏÑ±Ìï¥Ï§ò."
    resp = client.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[
            {
                "role": "system",
                "content": system
            },
            {
                "role": "user",
                "content": content[:1000]
            },
        ],
        temperature=0.7,
        max_tokens=800,
    )
    return re.sub(r"^.*?:\s*", "", resp.choices[0].message.content.strip())


def extract_tags(text: str) -> List[str]:
    prompt = f"Îã§Ïùå Í∏ÄÏóêÏÑú Ïã§Î¨¥ Ï§ëÏã¨ Î™ÖÏÇ¨ 5Í∞úÎ•º Ìï¥ÏãúÌÉúÍ∑∏(#ÌÇ§ÏõåÎìú) ÌòïÌÉúÎ°ú Ï∂îÏ∂úÌï¥Ï§ò. Í∏Ä: {text}"
    resp = client.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[
            {
                "role": "system",
                "content": "ÎãπÏã†ÏùÄ ÌÉúÍ∑∏ Ï∂îÏ∂ú Ï†ÑÎ¨∏Í∞ÄÏûÖÎãàÎã§."
            },
            {
                "role": "user",
                "content": prompt
            },
        ],
        temperature=0,
        max_tokens=50,
    )
    return re.findall(r"#(\w+)", resp.choices[0].message.content.strip())[:5]


def translate_text(text: str, lang: str) -> str:
    langs = {
        "English": "English",
        "Chinese": "Simplified Chinese",
        "Japanese": "Japanese"
    }
    target = langs.get(lang, lang)
    resp = client.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[
            {
                "role": "system",
                "content": f"Îã§ÏùåÏùÑ {target}Î°ú Î≤àÏó≠Ìï¥Ï§ò."
            },
            {
                "role": "user",
                "content": text
            },
        ],
        temperature=0.5,
        max_tokens=2000,
    )
    return resp.choices[0].message.content.strip()


def find_matching_image(tags: List[str], image_ws) -> str:
    data = image_ws.get_all_values()[1:]
    for row in data:
        for tag in tags:
            if tag in row[0]:
                return row[1]
    return ""


def now_str() -> str:
    return datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")


def process_regeneration():
    logging.basicConfig(level=logging.INFO)
    logging.info("üìå process_regeneration() ÏãúÏûë")

    src_ws = init_worksheet(SOURCE_DB_ID, "support business")
    prompt_ws = init_worksheet(SOURCE_DB_ID, "prompt")
    image_ws = init_worksheet(SOURCE_DB_ID, "image")
    info_ws = init_worksheet(TARGET_DB_ID, "information", [
        "ÏûëÏÑ±ÏùºÏãú", "origin tag", "ÏÇ¨Ïù¥Ìä∏ Î∂ÑÎ•ò", "Ï†úÎ™©", "ÎÇ¥Ïö©", "ÌÉúÍ∑∏", "ÏòÅÎ¨∏", "Ï§ëÎ¨∏", "ÏùºÎ¨∏",
        "ÌëúÏ†àÎ•†", "Ïù¥ÎØ∏ÏßÄurl"
    ])

    # 1) ÏõêÎ≥∏ Îç∞Ïù¥ÌÑ∞ Í∞ÄÏ†∏Ïò§Í∏∞ (Ïù¥Ï†Ñ 'filtered' Ï†úÍ±∞)
    rows = src_ws.get_all_values()[1:]

    # 2) ÌîÑÎ°¨ÌîÑÌä∏ Ï†ÑÏ≤¥ Í∞ÄÏ†∏Ïò§Í∏∞
    prompts = prompt_ws.get_all_values()[1:]

    total = 0
    # 3) Î™®Îì† ÌñâÏùÑ ÏàúÌöåÌïòÎ©∞ ÌîÑÎ°¨ÌîÑÌä∏ Îß§Ïπ≠ Î∞è Í∏Ä ÏÉùÏÑ±
    for row in rows:
        origin_tag = row[4] if len(row) > 4 else ""  # EÏó¥
        site_category = row[5] if len(row) > 5 else ""  # FÏó¥

        # 4) site_category, origin_tag, ÏÇ¨Ïö©Ïó¨Î∂Ä == 'Y' Î°úÎßå ÌîÑÎ°¨ÌîÑÌä∏ ÌïÑÌÑ∞ÎßÅ
        candidates = [
            p for p in prompts
            if len(p) >= 15 and p[2].strip() == site_category  # ÏÇ¨Ïù¥Ìä∏Î∂ÑÎ•ò
            and p[3].strip() == origin_tag  # Tag
            and p[4].strip() == "Y"  # ÌòÑÏû¨ÏÇ¨Ïö©Ïó¨Î∂Ä
        ]
        if not candidates:
            logging.warning(
                f"‚ö†Ô∏è Îß§Ïπ≠ÎêòÎäî ÌîÑÎ°¨ÌîÑÌä∏ ÏóÜÏùå: site={site_category}, tag={origin_tag}")
            continue

        cfg = random.choice(candidates)
        prompt_config = cfg[5:11]  # ÏûëÏÑ±Ïûê Ïó≠Ìï† ÏÑ§Î™Ö ~ Ï∂îÍ∞Ä ÏßÄÏãúÏÇ¨Ìï≠
        method = cfg[11]  # GPT Î™®Îç∏Î∞©Ïãù ('ÌïòÏù¥Î∏åÎ¶¨Îìú' or 'ÏùºÎ∞ò')
        interval = int(cfg[12])  # Í∏Ä Í∞ÑÍ≤©
        basic_model = cfg[13]  # Í∏∞Î≥∏ gpt
        advanced_model = cfg[14]  # Í≥†Í∏â gpt

        # 5) ÏÉùÏÑ± Í∞úÏàò Í≤∞Ï†ï
        count = interval + 1 if method == "ÌïòÏù¥Î∏åÎ¶¨Îìú" else interval
        selected_rows = random.sample(rows, min(count,
                                                len(rows)))  # Í∏∞Ï°¥ ÎûúÎç§ ÏÉòÌîåÎßÅ Ïú†ÏßÄ

        # 6) Í∏Ä ÏÉùÏÑ± Î£®ÌîÑ
        for idx, item in enumerate(selected_rows, start=1):
            use_model = advanced_model if (method == "ÌïòÏù¥Î∏åÎ¶¨Îìú"
                                           and idx == count) else basic_model
            original_title = item[1] if len(item) > 1 else ""
            original = item[2] if len(item) > 2 else ""

            content, score, _ = regenerate_unique_post(
                original_title, original, [r[2] for r in rows if len(r) > 2],
                prompt_config, use_model)
            new_title = regenerate_title(content)
            tags = extract_tags(content)
            en = translate_text(content, "English")
            zh = translate_text(content, "Chinese")
            ja = translate_text(content, "Japanese")
            img = find_matching_image(tags, image_ws)

            info_ws.append_row([
                now_str(), origin_tag, site_category, new_title, content,
                ", ".join(tags), en, zh, ja, f"{score:.2f}", img
            ])
            total += 1

    logging.info(f"üí∞ Ï¥ù Ï†ÄÏû•Îêú Í∏Ä Ïàò: {total}")
    return total


if __name__ == "__main__":
    process_regeneration()
