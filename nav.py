import os
import json
import datetime
import random
import logging
import re
import difflib
from typing import List, Tuple

import gspread
from google.oauth2.service_account import Credentials as GCredentials
import openai  # âœ… ë³€ê²½: ëª¨ë“ˆ ì „ì²´ import

# â”€â”€ ì„œë¹„ìŠ¤ ê³„ì • JSON ë¡œë“œ & ê²€ì¦ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
CREDENTIALS_JSON = os.getenv("GSHEET_CREDENTIALS_JSON", "")
if not CREDENTIALS_JSON:
    raise ValueError("âŒ í™˜ê²½ë³€ìˆ˜ 'GSHEET_CREDENTIALS_JSON'ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")
try:
    creds_info = json.loads(CREDENTIALS_JSON)
except json.JSONDecodeError as e:
    raise ValueError(f"âŒ SERVICE_ACCOUNT_JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
if "private_key" not in creds_info or not creds_info["private_key"].startswith(
        "-----BEGIN PRIVATE KEY-----"):
    raise ValueError("âŒ ì˜ëª»ëœ ì„œë¹„ìŠ¤ ê³„ì • JSONì…ë‹ˆë‹¤.")

# â–¶ Google Sheets/Drive ì¸ì¦ ê°ì²´ ìƒì„±
SCOPES = [
    "https://spreadsheets.google.com/feeds",
    "https://www.googleapis.com/auth/drive"
]
gs_creds = GCredentials.from_service_account_info(creds_info, scopes=SCOPES)

# âœ… OpenAI API í‚¤ ì„¤ì •
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    raise ValueError("âŒ í™˜ê²½ë³€ìˆ˜ 'OPENAI_API_KEY'ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")
openai.api_key = OPENAI_API_KEY

# ìƒìˆ˜ ì •ì˜
SIMILARITY_THRESHOLD = 0.6
MAX_RETRIES          = 5
SOURCE_DB_ID         = os.getenv("SOURCE_DB_ID")
TARGET_DB_ID         = os.getenv("TARGET_DB_ID")


def init_worksheet(sheet_id: str, sheet_name: str, header: List[str] = None):
    ws = gspread.authorize(gs_creds).open_by_key(sheet_id).worksheet(sheet_name)
    if header:
        first = ws.get_all_values()[:1]
        if not first or all(cell == "" for cell in first[0]):
            ws.clear()
            ws.append_row(header)
    return ws


def calculate_similarity(text1: str, text2: str) -> float:
    return difflib.SequenceMatcher(None, text1, text2).ratio()


def clean_content(text: str) -> str:
    return re.sub(r'(?m)^(ì„œë¡ |ë¬¸ì œ ìƒí™©|ì‹¤ë¬´ íŒ|ê²°ë¡ )[:\-]?\s*', "", text).strip()


def build_messages_from_prompt(
    prompt_config: List[str],
    title: str,
    content: str
) -> List[dict]:
    purpose, tone, para, emphasis, format_, etc = prompt_config
    system_msg = f"""{purpose}

{tone}

{para}

{emphasis}

{format_}

{etc}"""
    user_msg = f"""ë‹¤ìŒ ê¸€ì„ ì¤‘ë³µë˜ì§€ ì•Šë„ë¡ ì¬ì‘ì„±í•´ì¤˜:

ì œëª©: {title}
ë‚´ìš©: {content}"""
    return [
        {"role": "system", "content": system_msg.strip()},
        {"role": "user",   "content": user_msg.strip()},
    ]


def regenerate_unique_post(
    original_title: str,
    original: str,
    existing_texts: List[str],
    prompt_config: List[str],
    model: str,
) -> Tuple[str, float, int]:
    regen, score = original, 1.0
    for i in range(1, MAX_RETRIES + 1):
        messages = build_messages_from_prompt(
            prompt_config, original_title, original
        )
        etc_lower = prompt_config[-1].lower()
        if "3000ì" in etc_lower:
            max_tokens = 3000
        elif "2500ì" in etc_lower:
            max_tokens = 2500
        elif "2000ì" in etc_lower:
            max_tokens = 2000
        else:
            max_tokens = 3000

        # ğŸ”§ openai module í˜¸ì¶œë¡œ ë³€ê²½
        resp = openai.ChatCompletion.create(
            model=model,
            messages=messages,
            temperature=0.8,
            max_tokens=max_tokens,
        )
        candidate = clean_content(resp.choices[0].message.content.strip())
        sim = max(calculate_similarity(candidate, t) for t in existing_texts)
        if sim < SIMILARITY_THRESHOLD:
            return candidate, sim, i
        regen, score = candidate, sim

    return regen, score, MAX_RETRIES


def regenerate_title(content: str) -> str:
    system = "ë„ˆëŠ” ë§ˆì¼€íŒ… ì½˜í…ì¸  ì „ë¬¸ê°€ì•¼. ì•„ë˜ ë‚´ìš©ì„ ë³´ê³  í´ë¦­ì„ ìœ ë„í•˜ëŠ” ì§§ì€ ì œëª©ì„ ì‘ì„±í•´ì¤˜."
    resp = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": system},
            {"role": "user",   "content": content[:1000]},
        ],
        temperature=0.7,
        max_tokens=800,
    )
    return re.sub(r"^.*?:\s*", "", resp.choices[0].message.content.strip())


def extract_tags(text: str) -> List[str]:
    prompt = f"ë‹¤ìŒ ê¸€ì—ì„œ ì‹¤ë¬´ ì¤‘ì‹¬ ëª…ì‚¬ 5ê°œë¥¼ í•´ì‹œíƒœê·¸(#í‚¤ì›Œë“œ) í˜•íƒœë¡œ ì¶”ì¶œí•´ì¤˜. ê¸€: {text}"
    resp = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ íƒœê·¸ ì¶”ì¶œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
            {"role": "user",   "content": prompt},
        ],
        temperature=0,
        max_tokens=50,
    )
    return re.findall(r"#(\w+)", resp.choices[0].message.content.strip())[:5]


def translate_text(text: str, lang: str) -> str:
    langs  = {"English": "English", "Chinese": "Simplified Chinese", "Japanese": "Japanese"}
    target = langs.get(lang, lang)
    resp = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": f"ë‹¤ìŒì„ {target}ë¡œ ë²ˆì—­í•´ì¤˜."},
            {"role": "user",   "content": text},
        ],
        temperature=0.5,
        max_tokens=2000,
    )
    return resp.choices[0].message.content.strip()


def find_matching_image(tags: List[str], image_ws) -> str:
    data = image_ws.get_all_values()[1:]
    for row in data:
        if any(tag in row[0] for tag in tags):
            return row[1]
    return ""


def now_str() -> str:
    return datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")


def process_regeneration():
    logging.basicConfig(level=logging.INFO)
    logging.info("ğŸ“Œ process_regeneration() ì‹œì‘")

    src_ws    = init_worksheet(SOURCE_DB_ID, "health")
    prompt_ws = init_worksheet(SOURCE_DB_ID, "prompt")
    image_ws  = init_worksheet(SOURCE_DB_ID, "image")
    info_ws   = init_worksheet(
        TARGET_DB_ID, "information",
        ["ì‘ì„±ì¼ì‹œ","origin tag","ì‚¬ì´íŠ¸ ë¶„ë¥˜","ì œëª©","ë‚´ìš©","íƒœê·¸","ì˜ë¬¸","ì¤‘ë¬¸","ì¼ë¬¸","í‘œì ˆë¥ ","ì´ë¯¸ì§€url"]
    )

    rows    = src_ws.get_all_values()[1:]
    total   = 0

    # â”€â”€ í”„ë¡¬í”„íŠ¸ ì‹œíŠ¸ì— 'run_count' ì—´ ì¶”ê°€(ì—†ìœ¼ë©´) ë° ì¸ë±ìŠ¤ ê³„ì‚° â”€â”€
    header = prompt_ws.row_values(1)
    if 'run_count' not in header:
        prompt_ws.add_cols(1)  # âœ… ìˆ˜ì •: ì‘ë™ íšŸìˆ˜ ê¸°ë¡ ìœ„í•œ ì—´ ì¶”ê°€
        prompt_ws.update_cell(1, len(header) + 1, 'run_count')
        run_idx = len(header) + 1
    else:
        run_idx = header.index('run_count') + 1

    # â”€â”€ ê° í”„ë¡¬í”„íŠ¸ë³„ë¡œ 1cycle ìˆ˜í–‰ â”€â”€
    prompts = prompt_ws.get_all_values()[1:]
    for pr_idx, cfg in enumerate(prompts, start=2):  # pr_idx = ì‹¤ì œ ì‹œíŠ¸ í–‰ ë²ˆí˜¸
        if len(cfg) < 15:
            continue
        if cfg[4].strip().upper() != 'Y':  # í˜„ì¬ ì‚¬ìš© ì—¬ë¶€
            continue

        site_category = cfg[2].strip()
        origin_tag    = cfg[3].strip()
        interval      = int(cfg[12])
        basic_model   = cfg[13]
        advanced_model= cfg[14]

        # ê¸°ì¡´ ì‘ë™ íšŸìˆ˜ ì½ê¸°
        prev_count = int(cfg[run_idx-1]) if len(cfg) >= run_idx and cfg[run_idx-1].isdigit() else 0

        # ì†ŒìŠ¤ í–‰ ì¤‘ ì´ í”„ë¡¬í”„íŠ¸ì— ë§¤ì¹­ë˜ëŠ” í–‰ë“¤
        matching = [r for r in rows if len(r)>5 and r[5].strip()==site_category and r[4].strip()==origin_tag]
        if not matching:
            logging.warning(f"âš ï¸ ë§¤ì¹­ë˜ëŠ” ì†ŒìŠ¤ ì—†ìŒ: site={site_category}, tag={origin_tag}")
            continue

        # ì„ì˜ 1ê°œ í–‰ ì„ íƒ (1cycle)
        item = random.choice(matching)

        # ëª¨ë¸ ì„ ì •: intervalê¹Œì§€ basic, ê·¸ ë‹¤ìŒ cycleì— advanced
        if prev_count < interval:
            use_model     = basic_model
            new_count     = prev_count + 1
        else:
            use_model     = advanced_model
            new_count     = 0  # âœ… ìˆ˜ì •: advanced ì´í›„ ì¹´ìš´íŠ¸ ë¦¬ì…‹

        # â”€â”€ ì½˜í…ì¸  ìƒì„± ë° ì €ì¥ â”€â”€
        original_title = item[1] if len(item)>1 else ""
        original       = item[2] if len(item)>2 else ""

        content, score, _ = regenerate_unique_post(
            original_title, original,
            [r[2] for r in rows if len(r)>2],
            cfg[5:11], use_model
        )
        new_title = regenerate_title(content)
        tags      = extract_tags(content)
        en        = translate_text(content, "English")
        zh        = translate_text(content, "Chinese")
        ja        = translate_text(content, "Japanese")
        img       = find_matching_image(tags, image_ws)

        info_ws.append_row([
            now_str(), origin_tag, site_category, new_title, content,
            ", ".join(tags), en, zh, ja, f"{score:.2f}", img
        ])
        total += 1

        # í”„ë¡¬í”„íŠ¸ ì‹œíŠ¸ì— ìƒˆ ì‘ë™ íšŸìˆ˜ ê¸°ë¡
        prompt_ws.update_cell(pr_idx, run_idx, str(new_count))  # âœ… ìˆ˜ì •: cycle ìˆ˜ ì—…ë°ì´íŠ¸

    logging.info(f"ğŸ’° ì´ ì €ì¥ëœ ê¸€ ìˆ˜: {total}")
    return total


if __name__ == "__main__":
    process_regeneration()
