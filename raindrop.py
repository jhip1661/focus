import os, json, datetime, time, requests, logging, gspread
from bs4 import BeautifulSoup
from google.oauth2.service_account import Credentials as GCredentials
import openai

logging.basicConfig(level=logging.INFO)

# âœ… í™˜ê²½ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°
raw_json = os.getenv("GSHEET_CREDENTIALS_JSON")
if not raw_json:
    raise ValueError("âŒ í™˜ê²½ë³€ìˆ˜ 'GSHEET_CREDENTIALS_JSON'ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

try:
    # ğŸ¯ í•µì‹¬: \n ë³µì› (ì£¼ì˜: ê¼­ \\n â†’ \n ë³€í™˜ë§Œ ì ìš©í•´ì•¼ í•¨)
    fixed_json = raw_json.replace('\\n', '\n')

    # âœ… JSON íŒŒì‹±
    creds_dict = json.loads(fixed_json)

    # âœ… ì¸ì¦ ê°ì²´ ìƒì„±
    creds = GCredentials.from_service_account_info(creds_dict)
    gclient = gspread.authorize(creds)

    logging.info("âœ… Google Sheets ì¸ì¦ ì™„ë£Œ")
except Exception as e:
    logging.error(f"âŒ ì¸ì¦ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
    raise

# ğŸ“Œ ê¸°íƒ€ í™˜ê²½ë³€ìˆ˜
RAINDROP_TOKEN = os.getenv("RAINDROP_TOKEN")
GSHEET_ID = os.getenv("GSHEET_ID")
GPT_MODEL = "gpt-3.5-turbo"
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
openai.api_key = OPENAI_API_KEY

def extract_main_text(url):
    try:
        html = requests.get(url, timeout=10).text
        soup = BeautifulSoup(html, 'html.parser')
        for tag in soup(['script', 'style', 'nav', 'footer', 'aside']):
            tag.decompose()
        return ' '.join(soup.stripped_strings)[:5000]
    except Exception as e:
        logging.warning(f"[ë³¸ë¬¸ ì¶”ì¶œ ì‹¤íŒ¨] {e}")
        return None

def get_raindrop_prompt_by_tag(tags):
    sheet = gclient.open_by_key(GSHEET_ID).worksheet("prompt")
    rows = sheet.get_all_values()

    domestic_tag = "êµ­ë‚´ì§€ì›ì‚¬ì—…"
    domestic_prompt, global_prompt = None, None

    for row in rows[1:]:
        if len(row) >= 9 and row[1].strip().lower() == "raindrop" and row[3].strip().upper() == "Y":
            prompt_data = {
                "role": row[4],
                "conditions": row[5],
                "structure": row[6],
                "must_include": row[7],
                "conclusion": row[8],
                "extra": row[9] if len(row) > 9 else ""
            }
            if row[2].strip() == domestic_tag:
                domestic_prompt = prompt_data
            else:
                global_prompt = prompt_data

    return domestic_prompt if any(domestic_tag in tag for tag in tags) else global_prompt or domestic_prompt

def generate_blog_style_summary(title, url, text, tags):
    prompt_data = get_raindrop_prompt_by_tag(tags)
    if not prompt_data:
        return "[í”„ë¡¬í”„íŠ¸ ì •ë³´ ì—†ìŒ]"

    prompt = f"""{prompt_data['role']}

âœï¸ ì‘ì„± ì¡°ê±´:
{prompt_data['conditions']}

ğŸ§­ ê¸€ êµ¬ì„± ë°©ì‹:
{prompt_data['structure']}

ğŸ“Œ ë°˜ë“œì‹œ í¬í•¨í•  í•­ëª©:
{prompt_data['must_include']}

ğŸ¯ ë§ˆë¬´ë¦¬ ë¬¸ì¥:
{prompt_data['conclusion']}

ğŸ“ ì¶”ê°€ ì§€ì‹œì‚¬í•­:
{prompt_data['extra']}

---
ì§€ì›ì‚¬ì—… ì œëª©: {title}
ìŠ¤í¬ë©í•œ ë³¸ë¬¸:
{text}
"""

    for _ in range(3):
        try:
            response = openai.ChatCompletion.create(
                model=GPT_MODEL,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=2500,
                temperature=0.7
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            logging.warning(f"GPT ìƒì„± ì‹¤íŒ¨, ì¬ì‹œë„ ì¤‘: {e}")
            time.sleep(3)
    return "[GPT ìƒì„± ì‹¤íŒ¨]"

def append_to_fixed_sheet(row):
    sheet = gclient.open_by_key(GSHEET_ID).worksheet("support business")
    existing_titles = set(sheet.col_values(2))
    if row[1] not in existing_titles:
        sheet.append_row(row)

def fetch_and_process_raindrop():
    headers = {"Authorization": f"Bearer {RAINDROP_TOKEN}"}
    res = requests.get("https://api.raindrop.io/rest/v1/raindrops/0", headers=headers)

    if res.status_code != 200:
        raise Exception(f"Raindrop API í˜¸ì¶œ ì‹¤íŒ¨: {res.text}")

    data = res.json()
    if 'items' not in data:
        logging.error("âŒ Raindrop ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜")
        return 0

    items = data.get("items", [])
    added = 0
    for item in items:
        title = item.get("title")
        link = item.get("link")
        tags = item.get("tags", [])
        if not title or not link or not tags:
            continue
        content = extract_main_text(link)
        if not content:
            continue
        summary = generate_blog_style_summary(title, link, content, tags)
        now = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        tag_string = ", ".join(tags)
        row = [now, title, summary, link, tag_string]
        append_to_fixed_sheet(row)
        added += 1
    return added

print(repr(raw_json[:200]))  # ì‹œì‘ 200ê¸€ìë§Œ ì¶œë ¥

if __name__ == "__main__":
    fetch_and_process_raindrop()
